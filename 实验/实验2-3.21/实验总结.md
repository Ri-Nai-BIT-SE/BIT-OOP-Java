# 实验总结

## 实验：K-means聚类算法的实现与鸢尾花数据集分析

### 实验内容
实现K-means聚类算法，对Iris（鸢尾花）数据集进行聚类分析。数据集包含四个特征属性：花萼长度（sepal length）、花萼宽度（sepal width）、花瓣长度（petal length）和花瓣宽度（petal width）。要求将聚类结果输出到cluster.txt文件中。

### 实验思路
1. 数据预处理：
   - 读取Iris数据集，提取四个特征属性以及标签
   - 对数据进行标准化处理，使各个特征具有相同的尺度

2. K-means算法实现：
   - 随机初始化k个聚类中心
   - 计算每个样本点到各个聚类中心的欧氏距离
   - 将样本分配到距离最近的聚类中心所属的类
   - 重新计算每个类的中心点（均值）
   - 重复上述步骤直到聚类中心基本不变或达到最大迭代次数

3. 结果输出：
   - 将聚类结果（包含原始特征值和聚类标签）写入cluster.txt文件
   - 同时输出每个簇的中心点坐标

### 实验结果
从cluster.txt文件的内容可以看出：
1. 算法成功将150个样本分为3类（标签为0、1、2）
2. 聚类结果与原始数据的分类（Iris-setosa、Iris-versicolor、Iris-virginica）有较好的对应关系：
   - 簇0主要对应Iris-versicolor
   - 簇1主要对应Iris-setosa
   - 簇2主要对应Iris-virginica

3. 最终的聚类中心点为：
   - 簇0: (5.89,2.74,4.40,1.42) Iris-versicolor
   - 簇1: (5.01,3.42,1.46,0.24) Iris-setosa
   - 簇2: (6.85,3.08,5.70,2.08) Iris-virginica

### 实验心得
1. 算法实现方面：
   - K-means算法的实现相对简单，但需要注意一些细节，如初始中心点的选择、距离计算的准确性等
   - 对数据进行标准化处理，使各个特征具有相同的尺度，可以避免某些特征对聚类结果的影响过大
   - 使用欧氏距离作为距离度量方式，能够较好地反映样本间的相似度

2. 数据处理方面：
   - 鸢尾花数据集是机器学习中经典的数据集，特征维度适中，适合用来验证聚类算法的效果
   - 通过实验发现，不同的特征对聚类结果有不同的影响，特征的选择和预处理对聚类效果很重要

3. 结果分析方面：
   - 聚类结果比较好，每一个簇的大部分样本都来自于同一个类别
   - 聚类中心点与原始数据集的中心点比较接近，说明聚类结果比较准确


这次实验加深了我对机器学习中无监督学习算法的理解，也让我认识到了算法实现过程中需要注意的各种细节问题。通过实践，我更好地理解了聚类算法在实际应用中的优势和局限性。

<!-- java -->
这次实验同样让我对java语言有了更深入的了解，熟悉了java的语法，学会了如何使用java语言实现K-means算法。
